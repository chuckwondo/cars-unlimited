{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.0 64-bit ('cars-unlimited': pipenv)",
   "metadata": {
    "interpreter": {
     "hash": "2c9095245ecac54d79cccc65649c037c84ba256597e7a631c246c6f1e3a83440"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Cars Unlimited\n",
    "\n",
    "## Recommended Resources\n",
    "\n",
    "- [Geoprocessing with Python][1] by Chris Garrard\n",
    "- [Machine Learning Bookcamp][2] by Alexey Grigorev\n",
    "- [Machine Learning, Data Science and Deep Learning with Python][3] by Frank Kane\n",
    "- [Machine Learning with TensorFlow][4] by Nishant Shukla\n",
    "- [3Blue1Brown: Neural Networks][5] by Grant Sanderson\n",
    "- [Deep Learning with JavaScript][6] by Shanqing Cai, Stanley Bileschi, Eric D. Nielsen, and Francois Chollet\n",
    "\n",
    "## 1.1 Data Preprocessing and Visualization\n",
    "\n",
    "### Step 1. Download the images for this task\n",
    "\n",
    "- See <https://www.kaggle.com/ajaykgp12/cars-wagonr-swift>\n",
    "\n",
    "### Step 2. Parse the images in each class (folder) and get a list of images in each of the classes.\n",
    "\n",
    "- Use Python to walk through the classes and collect a list of images.\n",
    "- Get a list of images per class. This would yield a number per class.\n",
    "\n",
    "[1]: https://livebook.manning.com/book/geoprocessing-with-python/about-this-book/\n",
    "[2]: https://livebook.manning.com/book/machine-learning-bookcamp/welcome/v-7/\n",
    "[3]: https://livevideo.manning.com/module/92_1_1/machine-learning-data-science-and-deep-learning-with-python/getting-started/introduction?\n",
    "[4]: https://livebook.manning.com/book/machine-learning-with-tensorflow\n",
    "[5]: https://livevideo.manning.com/module/97_1_1/3blue1brown-neural-networks/neural-networks/but-what-is-a-neural-network%3f?\n",
    "[6]: https://livebook.manning.com/book/deep-learning-with-javascript/about-this-book/"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "from mpl_toolkits.axes_grid1 import ImageGrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treedir(root):\n",
    "    \"\"\"Return dict mirroring directory structure starting at given root.\n",
    "\n",
    "    Assumes each directory contains only directories or regular files, not both.\n",
    "    In a directory containing both, only the subdirectories are represented.\n",
    "    Each directory is represented by a dict nested within the dict of its parent\n",
    "    directory, associated with the directory name. Regular files are represented\n",
    "    by a list of file paths that include full relative paths from the root, and\n",
    "    the list is associated with the parent directory name as the key.\n",
    "    \"\"\"\n",
    "    def recur(walker):\n",
    "        dirpath, dirnames, filenames = next(walker)\n",
    "        return (\n",
    "            {dirname: recur(walker) for dirname in dirnames} if dirnames\n",
    "            else [os.path.join(dirpath, filename) for filename in filenames]\n",
    "        )\n",
    "\n",
    "    return recur(os.walk(root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "files_by_split_by_class = treedir('data')\n",
    "\n",
    "for split, files_by_class in files_by_split_by_class.items():\n",
    "    for class_, files in files_by_class.items():\n",
    "        print(split, class_, len(files))"
   ]
  },
  {
   "source": [
    "### Step 3. Use OpenCV to read images from each class, from train, validation and test splits.\n",
    "\n",
    "- Choose ten images at random from each class."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_images_per_class_per_split = 10\n",
    "\n",
    "# {\n",
    "#     split1: [\n",
    "#         (class1, img111),\n",
    "#         (class1, img112),\n",
    "#         ...,\n",
    "#         (class2, img121),\n",
    "#         ...,\n",
    "#     ],\n",
    "#     split2: [\n",
    "#         (class1, img211),\n",
    "#         (class1, img212),\n",
    "#         ...,\n",
    "#         (class2, img221),\n",
    "#         ...,\n",
    "#     ],\n",
    "#     ...\n",
    "# }\n",
    "random_labeled_images_by_split = {\n",
    "    split: [\n",
    "        (class_, cv2.imread(file))\n",
    "        for class_, files in files_by_class.items()\n",
    "        for file in random.choices(files, k=n_images_per_class_per_split)\n",
    "    ]\n",
    "    for split, files_by_class in files_by_split_by_class.items()\n",
    "}"
   ]
  },
  {
   "source": [
    "### Step 4. Display each image along with their label (class name) below it.\n",
    "\n",
    "- Use matplotlib to plot the images as a matrix."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# See https://stackoverflow.com/questions/46615554/how-to-display-multiple-images-in-one-figure-correctly\n",
    "\n",
    "def plot_labeled_images(labeled_images, *, nrows=10, ncols=2, figsize=(10, 50)):\n",
    "    fig, axes = plt.subplots(nrows=nrows, ncols=ncols, figsize=figsize)\n",
    "\n",
    "    # plot simple raster image on each sub-plot\n",
    "    for i, ax in enumerate(axes.flat):\n",
    "        # i runs from 0 to (nrows * ncols - 1)\n",
    "        # ax is equivalent with axes[r][c]\n",
    "        label, img = labeled_images[i]\n",
    "        ax.imshow(img)\n",
    "        ax.set_title(label)\n",
    "        ax.set_xticks([])\n",
    "        ax.set_yticks([])\n",
    "        \n",
    "    plt.tight_layout(True)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_labeled_images(random_labeled_images_by_split['train'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_labeled_images(random_labeled_images_by_split['validation'])"
   ]
  },
  {
   "source": [
    "### Step 5. Log your observations with random images.\n",
    "\n",
    "- Note the challenges in pose, color, lighting in the train and validation data.\n",
    "- What was your guess of the classes?\n",
    "\n",
    "Some images are rotated, cropped, or obstructed, which might cause problems.  Additionally, some images show only the front or rear of the vehicle, which might also present challenges.  Regarding lighting, some images show glare/reflections on the windows or body of the vehicle.\n",
    "\n",
    "Although the 2 classes of vehicle are quite similar, there does seem to be a reasonable difference in \"boxiness,\" where the wagonr is rather clearly more \"boxy\" (less rounded) than the swift, and also appears to be a bit taller."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}